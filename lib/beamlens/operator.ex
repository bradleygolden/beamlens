defmodule Beamlens.Operator do
  @moduledoc """
  GenServer that runs an operator in a continuous LLM-driven loop.

  The LLM has full control over timing via the `wait` tool. The loop runs:

  1. Collect snapshot
  2. Send to LLM with current state
  3. LLM returns action (set_state, send_notification, get_notifications, execute, wait, think)
  4. Execute action and loop

  The `wait` tool lets the LLM control its own cadence:
  - Normal operation: wait(30000) -- 30 seconds
  - Elevated concern: wait(5000) -- 5 seconds
  - Critical monitoring: wait(1000) -- 1 second

  ## State Model

  The operator maintains one of four states:
  - `:healthy` - Everything is normal
  - `:observing` - Something looks off, gathering more data
  - `:warning` - Elevated concern, but not critical
  - `:critical` - Active issue requiring immediate attention

  ## Example

      {:ok, pid} = Beamlens.Operator.start_link(
        name: {:via, Registry, {MyRegistry, :beam}},
        skill: Beamlens.Skill.Beam
      )
  """

  use GenServer

  alias Beamlens.LLM.Utils
  alias Beamlens.Operator.{Notification, Snapshot, Tools}
  alias Beamlens.Skill.Base, as: BaseSkill
  alias Beamlens.Telemetry

  alias Beamlens.Operator.Tools.{
    Execute,
    GetNotifications,
    GetSnapshot,
    GetSnapshots,
    SendNotification,
    SetState,
    TakeSnapshot,
    Think,
    Wait
  }

  alias Puck.Context
  alias Puck.Sandbox.Eval

  @max_llm_retries 3

  defstruct [
    :name,
    :skill,
    :client,
    :client_registry,
    :context,
    :pending_task,
    :pending_trace_id,
    notifications: [],
    snapshots: [],
    iteration: 0,
    state: :healthy,
    running: false,
    llm_retry_count: 0
  ]

  @doc """
  Starts an operator process.

  ## Options

    * `:name` - Optional process name for registration
    * `:skill` - Required module implementing `Beamlens.Skill`
    * `:client_registry` - Optional LLM provider configuration map
    * `:start_loop` - Whether to start the LLM loop on init (default: true)
    * `:compaction_max_tokens` - Token threshold for compaction (default: 50_000)
    * `:compaction_keep_last` - Messages to keep verbatim after compaction (default: 5)

  """
  def start_link(opts) do
    name = Keyword.get(opts, :name)

    if name do
      GenServer.start_link(__MODULE__, opts, name: name)
    else
      GenServer.start_link(__MODULE__, opts)
    end
  end

  @doc """
  Returns the current operator status.

  Returns a map with:
    * `:operator` - Domain atom (e.g., `:beam`)
    * `:state` - Current state (`:healthy`, `:observing`, `:warning`, `:critical`)
    * `:running` - Boolean indicating if the loop is active

  """
  def status(server) do
    GenServer.call(server, :status)
  end

  @doc """
  Stops the operator process.
  """
  def stop(server) do
    GenServer.stop(server)
  end

  @doc """
  Runs a single monitoring iteration without starting a persistent process.

  Useful for Oban-style scheduled execution where you want to run monitoring
  on a cron schedule rather than continuously.

  ## Arguments

    * `skill` - Module implementing `Beamlens.Skill`, or atom for built-in skill
    * `client_registry` - LLM provider configuration map

  ## Options

    * `:max_iterations` - Maximum LLM iterations before returning (default: 10)

  ## Returns

    * `{:ok, notifications}` - List of notifications sent during this run
    * `{:error, reason}` - If the skill couldn't be resolved or LLM failed

  ## Example

      # Run a single monitoring pass
      {:ok, notifications} = Beamlens.Operator.run_once(:beam, client_registry())

      # With options
      {:ok, notifications} = Beamlens.Operator.run_once(:beam, client_registry(), max_iterations: 5)

  ## Oban Integration

      defmodule MyApp.BeamlensWorker do
        use Oban.Worker, queue: :monitoring

        @impl true
        def perform(%{args: %{"skill" => skill_name}}) do
          skill = String.to_existing_atom(skill_name)
          {:ok, _notifications} = Beamlens.Operator.run_once(skill, client_registry())
          :ok
        end
      end

  """
  def run_once(skill, client_registry, opts \\ []) do
    with {:ok, {_name, skill_module}} <- resolve_skill(skill) do
      do_run_once(skill_module, client_registry, opts)
    end
  end

  defp resolve_skill(skill) when is_atom(skill) do
    Beamlens.Operator.Supervisor.resolve_skill(skill)
  end

  defp resolve_skill(skill_module) when is_atom(skill_module) do
    {:ok, {skill_module.id(), skill_module}}
  end

  defp do_run_once(skill, client_registry, opts) do
    max_iterations = Keyword.get(opts, :max_iterations, 10)
    client = build_puck_client(skill, client_registry, opts)

    run_state = %{
      skill: skill,
      client: client,
      context: Context.new(metadata: %{iteration: 0}),
      notifications: [],
      snapshots: [],
      state: :healthy,
      iteration: 0
    }

    run_loop(run_state, max_iterations)
  end

  defp run_loop(run_state, max_iterations) when run_state.iteration >= max_iterations do
    {:ok, run_state.notifications}
  end

  defp run_loop(run_state, max_iterations) do
    trace_id = Telemetry.generate_trace_id()
    input = build_input(run_state.state)

    context = %{
      run_state.context
      | metadata: Map.put(run_state.context.metadata, :trace_id, trace_id)
    }

    case Puck.call(run_state.client, input, context, output_schema: Tools.schema()) do
      {:ok, response, new_context} ->
        run_state = %{run_state | context: new_context}
        handle_run_once_action(response.content, run_state, max_iterations, trace_id)

      {:error, reason} ->
        {:error, {:llm_error, reason}}
    end
  end

  defp handle_run_once_action(%Wait{}, run_state, _max_iterations, _trace_id) do
    {:ok, run_state.notifications}
  end

  defp handle_run_once_action(%SetState{state: new_state}, run_state, max_iterations, _trace_id) do
    run_state = %{run_state | state: new_state, iteration: run_state.iteration + 1}
    run_loop(run_state, max_iterations)
  end

  defp handle_run_once_action(
         %SendNotification{
           type: type,
           summary: summary,
           severity: severity,
           snapshot_ids: snapshot_ids
         },
         run_state,
         max_iterations,
         trace_id
       ) do
    case resolve_snapshots(snapshot_ids, run_state.snapshots) do
      {:ok, snapshots} ->
        notification =
          Notification.new(%{
            operator: run_state.skill.id(),
            anomaly_type: type,
            severity: severity,
            summary: summary,
            snapshots: snapshots
          })

        :telemetry.execute(
          [:beamlens, :operator, :notification_sent],
          %{system_time: System.system_time()},
          %{operator: run_state.skill.id(), trace_id: trace_id, notification: notification}
        )

        run_state = %{
          run_state
          | notifications: run_state.notifications ++ [notification],
            iteration: run_state.iteration + 1
        }

        run_loop(run_state, max_iterations)

      {:error, reason} ->
        new_context = Utils.add_result(run_state.context, %{error: reason})
        run_state = %{run_state | context: new_context, iteration: run_state.iteration + 1}
        run_loop(run_state, max_iterations)
    end
  end

  defp handle_run_once_action(%TakeSnapshot{}, run_state, max_iterations, _trace_id) do
    data = run_state.skill.snapshot()
    snapshot = Snapshot.new(data)
    new_context = Utils.add_result(run_state.context, snapshot)

    run_state = %{
      run_state
      | context: new_context,
        snapshots: run_state.snapshots ++ [snapshot],
        iteration: run_state.iteration + 1
    }

    run_loop(run_state, max_iterations)
  end

  defp handle_run_once_action(%GetSnapshot{id: id}, run_state, max_iterations, _trace_id) do
    result =
      case Enum.find(run_state.snapshots, fn s -> s.id == id end) do
        nil -> %{error: "snapshot_not_found", id: id}
        snapshot -> snapshot
      end

    new_context = Utils.add_result(run_state.context, result)
    run_state = %{run_state | context: new_context, iteration: run_state.iteration + 1}
    run_loop(run_state, max_iterations)
  end

  defp handle_run_once_action(
         %GetSnapshots{limit: limit, offset: offset},
         run_state,
         max_iterations,
         _trace_id
       ) do
    offset = offset || 0
    snapshots = Enum.drop(run_state.snapshots, offset)
    snapshots = if limit, do: Enum.take(snapshots, limit), else: snapshots

    new_context = Utils.add_result(run_state.context, snapshots)
    run_state = %{run_state | context: new_context, iteration: run_state.iteration + 1}
    run_loop(run_state, max_iterations)
  end

  defp handle_run_once_action(%GetNotifications{}, run_state, max_iterations, _trace_id) do
    new_context = Utils.add_result(run_state.context, run_state.notifications)
    run_state = %{run_state | context: new_context, iteration: run_state.iteration + 1}
    run_loop(run_state, max_iterations)
  end

  defp handle_run_once_action(%Execute{code: lua_code}, run_state, max_iterations, _trace_id) do
    result =
      case Eval.eval(:lua, lua_code, callbacks: merged_callbacks(run_state.skill)) do
        {:ok, result} -> result
        {:error, reason} -> %{error: inspect(reason)}
      end

    new_context = Utils.add_result(run_state.context, result)
    run_state = %{run_state | context: new_context, iteration: run_state.iteration + 1}
    run_loop(run_state, max_iterations)
  end

  defp handle_run_once_action(%Think{thought: thought}, run_state, max_iterations, _trace_id) do
    result = %{thought: thought, recorded: true}
    new_context = Utils.add_result(run_state.context, result)
    run_state = %{run_state | context: new_context, iteration: run_state.iteration + 1}
    run_loop(run_state, max_iterations)
  end

  @impl true
  def init(opts) do
    skill = Keyword.fetch!(opts, :skill)
    name = Keyword.get(opts, :name)
    client_registry = Keyword.get(opts, :client_registry)
    start_loop = Keyword.get(opts, :start_loop, true)
    client = build_puck_client(skill, client_registry, opts)

    state = %__MODULE__{
      name: name,
      skill: skill,
      client: client,
      client_registry: client_registry,
      context: Context.new(metadata: %{iteration: 0}),
      iteration: 0,
      state: :healthy,
      running: start_loop
    }

    emit_telemetry(:started, state)

    if start_loop do
      {:ok, state, {:continue, :loop}}
    else
      {:ok, state}
    end
  end

  @impl true
  def handle_continue(:loop, state) do
    trace_id = Telemetry.generate_trace_id()

    emit_telemetry(:iteration_start, state, %{
      trace_id: trace_id,
      iteration: state.iteration,
      operator_state: state.state
    })

    input = build_input(state.state)
    context = %{state.context | metadata: Map.put(state.context.metadata, :trace_id, trace_id)}

    task =
      Task.async(fn ->
        Puck.call(state.client, input, context, output_schema: Tools.schema())
      end)

    {:noreply, %{state | pending_task: task, pending_trace_id: trace_id}}
  end

  @impl true
  def handle_info({ref, result}, %{pending_task: %Task{ref: ref}} = state) do
    Process.demonitor(ref, [:flush])
    state = %{state | pending_task: nil}

    case result do
      {:ok, response, new_context} ->
        state = %{state | context: new_context, llm_retry_count: 0}
        handle_action(response.content, state, state.pending_trace_id)

      {:error, reason} ->
        handle_llm_error(state, reason)
    end
  end

  def handle_info({:DOWN, ref, :process, _pid, reason}, %{pending_task: %Task{ref: ref}} = state) do
    handle_llm_error(state, {:task_crashed, reason})
  end

  def handle_info(:continue_loop, state) do
    {:noreply, state, {:continue, :loop}}
  end

  def handle_info(msg, state) do
    emit_telemetry(:unexpected_message, state, %{message: inspect(msg)})
    {:noreply, state}
  end

  @impl true
  def handle_call(:status, _from, state) do
    status = %{
      operator: state.skill.id(),
      state: state.state,
      running: state.running
    }

    {:reply, status, state}
  end

  @impl true
  def terminate(_reason, %{pending_task: %Task{} = task} = _state) do
    Task.shutdown(task, :brutal_kill)
    :ok
  end

  def terminate(_reason, _state), do: :ok

  defp handle_llm_error(state, reason) do
    new_retry_count = state.llm_retry_count + 1

    emit_telemetry(:llm_error, state, %{
      trace_id: state.pending_trace_id,
      reason: reason,
      retry_count: new_retry_count,
      will_retry: new_retry_count < @max_llm_retries
    })

    if new_retry_count < @max_llm_retries do
      delay = :timer.seconds(round(:math.pow(2, new_retry_count - 1)))
      Process.send_after(self(), :continue_loop, delay)

      {:noreply,
       %{state | pending_task: nil, pending_trace_id: nil, llm_retry_count: new_retry_count}}
    else
      {:noreply,
       %{state | pending_task: nil, pending_trace_id: nil, running: false, llm_retry_count: 0}}
    end
  end

  defp handle_action(%SetState{state: new_state, reason: reason}, state, trace_id) do
    emit_telemetry(:state_change, state, %{
      trace_id: trace_id,
      from: state.state,
      to: new_state,
      reason: reason
    })

    new_state = %{state | state: new_state, iteration: state.iteration + 1, pending_trace_id: nil}
    {:noreply, new_state, {:continue, :loop}}
  end

  defp handle_action(
         %SendNotification{
           type: type,
           summary: summary,
           severity: severity,
           snapshot_ids: snapshot_ids
         },
         state,
         trace_id
       ) do
    case resolve_snapshots(snapshot_ids, state.snapshots) do
      {:ok, snapshots} ->
        notification = build_notification(state, type, summary, severity, snapshots)

        emit_telemetry(:notification_sent, state, %{
          trace_id: trace_id,
          notification: notification
        })

        new_state = %{
          state
          | notifications: state.notifications ++ [notification],
            iteration: state.iteration + 1,
            pending_trace_id: nil
        }

        {:noreply, new_state, {:continue, :loop}}

      {:error, reason} ->
        emit_telemetry(:notification_failed, state, %{trace_id: trace_id, reason: reason})

        new_context = Utils.add_result(state.context, %{error: reason})

        new_state = %{
          state
          | context: new_context,
            iteration: state.iteration + 1,
            pending_trace_id: nil
        }

        {:noreply, new_state, {:continue, :loop}}
    end
  end

  defp handle_action(%GetNotifications{}, state, trace_id) do
    notifications = state.notifications

    emit_telemetry(:get_notifications, state, %{
      trace_id: trace_id,
      count: length(notifications)
    })

    new_context = Utils.add_result(state.context, notifications)

    new_state = %{
      state
      | context: new_context,
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state, {:continue, :loop}}
  end

  defp handle_action(%TakeSnapshot{}, state, trace_id) do
    data = collect_snapshot(state)
    snapshot = Snapshot.new(data)

    emit_telemetry(:take_snapshot, state, %{trace_id: trace_id, snapshot_id: snapshot.id})

    new_context = Utils.add_result(state.context, snapshot)

    new_state = %{
      state
      | context: new_context,
        snapshots: state.snapshots ++ [snapshot],
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state, {:continue, :loop}}
  end

  defp handle_action(%GetSnapshot{id: id}, state, trace_id) do
    emit_telemetry(:get_snapshot, state, %{trace_id: trace_id, snapshot_id: id})

    result =
      case Enum.find(state.snapshots, fn s -> s.id == id end) do
        nil -> %{error: "snapshot_not_found", id: id}
        snapshot -> snapshot
      end

    new_context = Utils.add_result(state.context, result)

    new_state = %{
      state
      | context: new_context,
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state, {:continue, :loop}}
  end

  defp handle_action(%GetSnapshots{limit: limit, offset: offset}, state, trace_id) do
    offset = offset || 0
    snapshots = Enum.drop(state.snapshots, offset)

    snapshots =
      if limit do
        Enum.take(snapshots, limit)
      else
        snapshots
      end

    emit_telemetry(:get_snapshots, state, %{trace_id: trace_id, count: length(snapshots)})

    new_context = Utils.add_result(state.context, snapshots)

    new_state = %{
      state
      | context: new_context,
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state, {:continue, :loop}}
  end

  defp handle_action(%Execute{code: lua_code}, state, trace_id) do
    emit_telemetry(:execute_start, state, %{trace_id: trace_id, code: lua_code})

    result =
      case Eval.eval(:lua, lua_code, callbacks: merged_callbacks(state.skill)) do
        {:ok, result} ->
          emit_telemetry(:execute_complete, state, %{
            trace_id: trace_id,
            code: lua_code,
            result: result
          })

          result

        {:error, reason} ->
          emit_telemetry(:execute_error, state, %{
            trace_id: trace_id,
            code: lua_code,
            reason: reason
          })

          %{error: inspect(reason)}
      end

    new_context = Utils.add_result(state.context, result)

    new_state = %{
      state
      | context: new_context,
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state, {:continue, :loop}}
  end

  defp handle_action(%Wait{ms: ms}, state, trace_id) do
    emit_telemetry(:wait, state, %{trace_id: trace_id, ms: ms})
    Process.send_after(self(), :continue_loop, ms)

    fresh_context = Context.new(metadata: %{iteration: state.iteration + 1})

    new_state = %{
      state
      | context: fresh_context,
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state}
  end

  defp handle_action(%Think{thought: thought}, state, trace_id) do
    emit_telemetry(:think, state, %{trace_id: trace_id, thought: thought})

    result = %{thought: thought, recorded: true}
    new_context = Utils.add_result(state.context, result)

    new_state = %{
      state
      | context: new_context,
        iteration: state.iteration + 1,
        pending_trace_id: nil
    }

    {:noreply, new_state, {:continue, :loop}}
  end

  defp collect_snapshot(state) do
    state.skill.snapshot()
  end

  defp build_input(operator_state) do
    "Current state: #{operator_state}"
  end

  defp build_notification(state, type, summary, severity, snapshots) do
    Notification.new(%{
      operator: state.skill.id(),
      anomaly_type: type,
      severity: severity,
      summary: summary,
      snapshots: snapshots
    })
  end

  defp resolve_snapshots([], _stored_snapshots) do
    {:error, "snapshot_ids required: notifications must reference at least one snapshot"}
  end

  defp resolve_snapshots(ids, stored_snapshots) do
    snapshot_map = Map.new(stored_snapshots, fn s -> {s.id, s} end)
    {found, missing} = Enum.split_with(ids, &Map.has_key?(snapshot_map, &1))

    if missing == [] do
      {:ok, Enum.map(found, &Map.fetch!(snapshot_map, &1))}
    else
      {:error, "snapshots not found: #{Enum.join(missing, ", ")}"}
    end
  end

  defp build_puck_client(skill, client_registry, opts) do
    system_prompt = skill.system_prompt()
    callback_docs = skill.callback_docs() <> "\n" <> BaseSkill.callback_docs()

    backend_config =
      %{
        function: "OperatorLoop",
        args_format: :auto,
        args: fn messages ->
          %{
            messages: Utils.format_messages_for_baml(messages),
            system_prompt: system_prompt,
            callback_docs: callback_docs
          }
        end,
        path: Application.app_dir(:beamlens, "priv/baml_src")
      }
      |> Utils.maybe_add_client_registry(client_registry)

    Puck.Client.new(
      {Puck.Backends.Baml, backend_config},
      hooks: Beamlens.Telemetry.Hooks,
      auto_compaction: build_compaction_config(opts)
    )
  end

  defp build_compaction_config(opts) do
    max_tokens = Keyword.get(opts, :compaction_max_tokens, 50_000)
    keep_last = Keyword.get(opts, :compaction_keep_last, 5)

    {:summarize,
     max_tokens: max_tokens, keep_last: keep_last, prompt: operator_compaction_prompt()}
  end

  defp operator_compaction_prompt do
    """
    Summarize this monitoring session, preserving:
    - What anomalies or concerns were detected
    - Current system state and trend direction
    - Snapshot IDs referenced (preserve exact IDs)
    - Key metric values that informed decisions
    - Any notifications sent and their reasons

    Be concise. This summary will be used to continue monitoring.
    """
  end

  defp emit_telemetry(event, state, extra \\ %{}) do
    :telemetry.execute(
      [:beamlens, :operator, event],
      %{system_time: System.system_time()},
      Map.merge(
        %{operator: state.skill.id()},
        extra
      )
    )
  end

  defp merged_callbacks(skill) do
    Map.merge(BaseSkill.callbacks(), skill.callbacks())
  end
end
